import mne
import glob
import matplotlib
import matplotlib.pyplot as plt

matplotlib.use('Qt5Agg')


""" Code to read the data and convert EDF into FIF format. """

# files_name = [f.split('/')[10].split('.')[0] for f in [file for file in glob.glob('/Users/riccardotedoldi/Desktop/ais/I/sem2/abns/project/eeg-during-mental-arithmetic-tasks-1.0.0/*.edf')]]
# path_files  = glob.glob('/Users/riccardotedoldi/Desktop/ais/I/sem2/abns/project/eeg-during-mental-arithmetic-tasks-1.0.0/*.edf')

# # read data
# # convert to FIF
# for name, file in zip(files_name, path_files):
#     raw = mne.io.read_raw_edf(file) 
#     # save as FIF
#     raw.save(f'/Users/riccardotedoldi/Desktop/ais/I/sem2/abns/project/eeg-during-mental-arithmetic-tasks-1.0.0/{name}.fif')
    


""" Code to read the data and plot it. """
import numpy as np

# read data eeg
import mne
from mne.datasets import multimodal

import glob
import os

import matplotlib.pyplot as plt

import math

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

from tqdm import tqdm

fname_raw = os.path.join(multimodal.data_path(), 'multimodal_raw.fif')

raw = mne.io.read_raw_fif(fname_raw)


d = raw.get_data()


number_samples = 4000

data = []
label = []

window = 50
batch = 128

min = 0
max = window

for _ in tqdm(range(number_samples)):
    data.append(torch.Tensor(d[:,min:max]))
    min = min + window
    max = max + window
    # max_temp = max + window
    label.append(torch.Tensor(d[:,min:max]))

# delete the raw data
del d

t_sample = torch.Tensor(number_samples, data[0].shape[0], data[0].shape[1])
t_label = torch.Tensor(number_samples, label[0].shape[0], label[0].shape[1])

for i in range(number_samples):
    t_sample[i] = data[i]
    t_label[i] = label[i]
    
# add cls token
cls_ = torch.zeros(number_samples, 1, data[0].shape[1])

t_sample = torch.cat((cls_, t_sample), dim=1)

cls_ = torch.zeros(number_samples, 1, label[0].shape[1])

t_label = torch.cat((cls_, t_label), dim=1)

del cls_

print()
print('#'*len('data shape: '+str(t_sample[0].shape)))
print('data shape: ', t_sample.shape)
print('label shape: ', t_label.shape)
print('#'*len('data shape: '+str(t_sample[0].shape)))

s_train = int(number_samples*0.8)
s_test = number_samples - s_train

print()
print('#'*len('data shape: '+str(t_sample[0].shape)))
print('sample train: ', s_train)
print('sample test: ', s_test)
print()
print()
print()

data = torch.utils.data.TensorDataset(t_sample, t_label)
training_samples, validation_samples = torch.utils.data.random_split(data, [s_train, s_test])

print()
print('#'*len('data shape: '+str(t_sample[0].shape)))
print('sample train shape: ', len(training_samples))
print('sample test shape: ', len(validation_samples))
print()
print()
print()

train = torch.utils.data.DataLoader(training_samples, batch_size=batch, shuffle=True)
val = torch.utils.data.DataLoader(validation_samples, batch_size=batch, shuffle=False)


# Example of MultiHeadAttention
def MultiHeadAttention(query, key, value, mask=None, dropout=None):
    d_k = query.size(-1)
    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)
    if mask is not None:
        scores = scores.masked_fill(mask == 0, -1e9)
    p_attn = F.softmax(scores, dim = -1)
    if dropout is not None:
        p_attn = dropout(p_attn)
    return torch.matmul(p_attn, value), p_attn



# result, attn_map = MultiHeadAttention(t_sample, t_sample, t_label)

# print()
# print('#'*len('data shape: '+str(t_sample[0].shape)))
# print('result shape: ', result.shape)
# print('attn_map shape: ', attn_map.shape)
# print('#'*len('data shape: '+str(t_sample[0].shape)))


# plt.imshow(attn_map[0].detach().numpy())



class TransformerEncoderLayer(nn.Module):
    def __init__(self, dim_emb, nhead: int = 2, dim_feedforward: int = 60, dropout: float =0.1, activation = nn.GELU):
        super(TransformerEncoderLayer, self).__init__()
        
        self.attn = nn.MultiheadAttention(dim_emb, nhead, dropout=dropout)
        
        # Implementation of Feedforward model
        self.linear1 = nn.Linear(dim_emb, dim_feedforward)
        self.dropout = nn.Dropout(dropout)
        self.linear2 = nn.Linear(dim_feedforward, dim_emb)

        self.norm1 = nn.LayerNorm(dim_emb)
        self.norm2 = nn.LayerNorm(dim_emb)
        
        self.dropout1 = nn.Dropout(dropout)
        self.dropout2 = nn.Dropout(dropout)

        self.activation = activation()

    def forward(self, data, label, src_mask=None, src_key_padding_mask=None):
        
        # MultiHeadAttention
        x = self.attn(data, data, data, attn_mask=src_mask, key_padding_mask=src_key_padding_mask)[0]
        
        # add & norm
        x = data + self.dropout1(x)
        x = self.norm1(x)
        
        # Implementation of Feedforward model
        x1 = self.linear2(self.dropout(self.activation(self.linear1(x))))
        
        # add & norm
        x = x + self.dropout2(x1)
        x = self.norm2(x)
        
        return x        

class MLP(nn.Module):
    def __init__(self, dim_emb, dim_feedforward: int = 300, dropout: float =0.1, activation = nn.GELU):
        super(MLP, self).__init__()
        
        # Implementation of Feedforward model
        self.linear1 = nn.Linear(dim_emb, dim_feedforward)
        self.linear2 = nn.Linear(dim_feedforward, label[0].shape[1])
        
        self.dropout = nn.Dropout(dropout)
        self.activation = activation()

    def forward(self, x):
        
        x = self.linear2(self.dropout(self.activation(self.linear1(x))))    
            
        return x

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
    
        self.te = TransformerEncoderLayer(t_sample.shape[2])
        self.mlp = MLP(t_sample.shape[2])
        
    def forward(self, data, label):
        x = self.te(data, label)
        x = self.mlp(x[:,:x.shape[1]-1])
        return x


# nn.CrossEntropyLoss()
def se_loss(y_pred, y_true):
    squared_error = abs(y_pred - y_true)
    # squared_error = (y_pred - y_true)**2
    loss = torch.sum(squared_error)/y_pred.shape[0]
    return loss

def training(net, train, optimizer, criterion = se_loss, epochs: int = 10):
    samples = 0.0
    cumulative_loss = 0.0
    cumulative_accuracy = 0.0

    # set the network in the training mode
    net.train()

    for i in range(epochs):
        for data, label in tqdm(train):
            data , label = data.to(device), label.to(device)
            # forward + backward + optimize
            outputs = net(data, label)
            loss = criterion(outputs, label[:,:label.shape[1]-1])
            loss.backward()
            optimizer.step()
        
            # zero the parameter gradients
            optimizer.zero_grad()
        
            # calculate the loss and accuracy
            samples += len(data)
            cumulative_loss += loss.item()
            # cumulative_accuracy += (outputs.argmax(1) == label).sum().item()
        
        # print statistics
        # print('epoch: %d, loss: %.3f, accuracy: %.3f' % (i + 1, cumulative_loss / samples, cumulative_accuracy / samples))
        print(f'epoch: {i + 1}, loss: {round(cumulative_loss / samples,4)}')
        
def test(net, test, criterion = se_loss, epochs: int = 10):
    samples = 0.0
    cumulative_loss = 0.0
    cumulative_accuracy = 0.0

    # set the network in the training mode
    net.eval()

    # disable gradient calculation
    with torch.no_grad():
        for data, label in tqdm(test):
            data, label = data.to(device), label.to(device)
            # forward + backward + optimize
            outputs = net(data, label)
            loss = criterion(outputs, label[:,:label.shape[1]-1])
        
            # calculate the loss and accuracy
            samples += len(data)
            cumulative_loss += loss.item()
            # cumulative_accuracy += (outputs.argmax(1) == label).sum().item()
        
        # print statistics
        # print('epoch: %d, loss: %.3f, accuracy: %.3f' % (i + 1, cumulative_loss / samples, cumulative_accuracy / samples))
        print(f'epoch: {i + 1}, loss: {round(cumulative_loss / samples,4)}')

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)      
    
net = Net().cuda()
print(net)

training(net, train, optimizer = optim.AdamW(net.parameters(), lr=0.001), epochs=60)
print('Finished Training')
print()
print('Testing the network on the test data')
print()
test(net, val)
    








# plot data eeg
# raw.plot()

# # apply bandpass filter
# raw.filter(1, 40)

# # extract events + remove eye blinks
# events = mne.find_events(raw)
# epochs = mne.Epochs(raw, events, tmin=-1, tmax=1, baseline=None, preload=True)

# # ICA
# ica = mne.preprocessing.ICA(n_components=20, random_state=42)
# ica.fit(epochs)
# ica.apply(epochs)



'''

window = 10

(uri) rickbook@rickbook:~/document/neuro/project-abns/project-abns$ python experiments/predict_signal_from_signal.py 
Opening raw data file /home/rickbook/mne_data/MNE-multimodal-data/multimodal_raw.fif...
    Read a total of 7 projection items:
        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle
        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle
    Range : 183600 ... 576599 =    305.687 ...   960.014 secs
Ready.
100%|████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:00<00:00, 14149.80it/s]

#################################
data shape:  torch.Size([4000, 317, 10])
label shape:  torch.Size([4000, 317, 10])
#################################

#################################
sample train:  3200
sample test:  800




#################################
sample train shape:  3200
sample test shape:  800



cuda:0
Net(
  (te): TransformerEncoderLayer(
    (attn): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=10, out_features=10, bias=True)
    )
    (linear1): Linear(in_features=10, out_features=60, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (linear2): Linear(in_features=60, out_features=10, bias=True)
    (norm1): LayerNorm((10,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((10,), eps=1e-05, elementwise_affine=True)
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (activation): GELU(approximate='none')
  )
  (mlp): MLP(
    (linear1): Linear(in_features=10, out_features=300, bias=True)
    (linear2): Linear(in_features=300, out_features=10, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (activation): GELU(approximate='none')
  )
)
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 25.21it/s]
epoch: 1, loss: 1.8542
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.15it/s]
epoch: 2, loss: 1.4577
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.15it/s]
epoch: 3, loss: 1.2357
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 67.90it/s]
epoch: 4, loss: 1.0798
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.13it/s]
epoch: 5, loss: 0.9594
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.62it/s]
epoch: 6, loss: 0.8622
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.02it/s]
epoch: 7, loss: 0.7818
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.24it/s]
epoch: 8, loss: 0.7141
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.03it/s]
epoch: 9, loss: 0.6565
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.69it/s]
epoch: 10, loss: 0.6072
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.19it/s]
epoch: 11, loss: 0.5648
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.32it/s]
epoch: 12, loss: 0.528
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.10it/s]
epoch: 13, loss: 0.4959
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.38it/s]
epoch: 14, loss: 0.4676
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.20it/s]
epoch: 15, loss: 0.4425
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.13it/s]
epoch: 16, loss: 0.4201
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 62.74it/s]
epoch: 17, loss: 0.4
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.28it/s]
epoch: 18, loss: 0.3818
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 67.95it/s]
epoch: 19, loss: 0.3654
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.66it/s]
epoch: 20, loss: 0.3504
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.06it/s]
epoch: 21, loss: 0.3367
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.10it/s]
epoch: 22, loss: 0.3241
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.10it/s]
epoch: 23, loss: 0.3125
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.20it/s]
epoch: 24, loss: 0.3018
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 67.80it/s]
epoch: 25, loss: 0.2918
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 67.98it/s]
epoch: 26, loss: 0.2826
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 67.42it/s]
epoch: 27, loss: 0.274
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.00it/s]
epoch: 28, loss: 0.2659
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.32it/s]
epoch: 29, loss: 0.2583
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.04it/s]
epoch: 30, loss: 0.2512
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.74it/s]
epoch: 31, loss: 0.2445
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 67.80it/s]
epoch: 32, loss: 0.2382
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.25it/s]
epoch: 33, loss: 0.2323
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.60it/s]
epoch: 34, loss: 0.2267
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.07it/s]
epoch: 35, loss: 0.2213
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 67.92it/s]
epoch: 36, loss: 0.2164
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.17it/s]
epoch: 37, loss: 0.2116
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 67.88it/s]
epoch: 38, loss: 0.2071
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.02it/s]
epoch: 39, loss: 0.2028
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 67.77it/s]
epoch: 40, loss: 0.1987
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.38it/s]
epoch: 41, loss: 0.1948
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 67.97it/s]
epoch: 42, loss: 0.1911
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.49it/s]
epoch: 43, loss: 0.1875
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.18it/s]
epoch: 44, loss: 0.184
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 67.99it/s]
epoch: 45, loss: 0.1807
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.07it/s]
epoch: 46, loss: 0.1776
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 67.89it/s]
epoch: 47, loss: 0.1745
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.19it/s]
epoch: 48, loss: 0.1716
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.16it/s]
epoch: 49, loss: 0.1687
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.06it/s]
epoch: 50, loss: 0.166
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 67.67it/s]
epoch: 51, loss: 0.1634
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 67.94it/s]
epoch: 52, loss: 0.161
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.34it/s]
epoch: 53, loss: 0.1586
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.10it/s]
epoch: 54, loss: 0.1562
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.00it/s]
epoch: 55, loss: 0.154
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.13it/s]
epoch: 56, loss: 0.1518
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.17it/s]
epoch: 57, loss: 0.1497
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 67.90it/s]
epoch: 58, loss: 0.1476
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.25it/s]
epoch: 59, loss: 0.1456
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 68.19it/s]
epoch: 60, loss: 0.1437
Finished Training

Testing the network on the test data

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 131.45it/s]
epoch: 4000, loss: 0.0359
(uri) rickbook@rickbook:~/document/neuro/project-abns/project-abns$ python experiments/predict_signal_from_signal.py 
Opening raw data file /home/rickbook/mne_data/MNE-multimodal-data/multimodal_raw.fif...
    Read a total of 7 projection items:
        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle
        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle
    Range : 183600 ... 576599 =    305.687 ...   960.014 secs
Ready.
100%|████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:00<00:00, 17958.55it/s]

#################################
data shape:  torch.Size([4000, 317, 10])
label shape:  torch.Size([4000, 317, 10])
#################################

#################################
sample train:  3200
sample test:  800




#################################
sample train shape:  3200
sample test shape:  800



cuda:0
Net(
  (te): TransformerEncoderLayer(
    (attn): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=10, out_features=10, bias=True)
    )
    (linear1): Linear(in_features=10, out_features=60, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (linear2): Linear(in_features=60, out_features=10, bias=True)
    (norm1): LayerNorm((10,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((10,), eps=1e-05, elementwise_affine=True)
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (activation): GELU(approximate='none')
  )
  (mlp): MLP(
    (linear1): Linear(in_features=10, out_features=300, bias=True)
    (linear2): Linear(in_features=300, out_features=10, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (activation): GELU(approximate='none')
  )
)
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 51.33it/s]
epoch: 1, loss: 3.1744
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 136.34it/s]
epoch: 2, loss: 2.3375
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 142.46it/s]
epoch: 3, loss: 1.8881
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 141.38it/s]
epoch: 4, loss: 1.589
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 140.22it/s]
epoch: 5, loss: 1.3702
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 136.79it/s]
epoch: 6, loss: 1.2024
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 140.69it/s]
epoch: 7, loss: 1.0701
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 140.68it/s]
epoch: 8, loss: 0.9644
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 140.08it/s]
epoch: 9, loss: 0.8786
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 139.11it/s]
epoch: 10, loss: 0.8077
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 140.56it/s]
epoch: 11, loss: 0.7483
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 141.87it/s]
epoch: 12, loss: 0.6976
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 137.95it/s]
epoch: 13, loss: 0.6538
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 142.59it/s]
epoch: 14, loss: 0.6156
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 139.73it/s]
epoch: 15, loss: 0.5819
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 139.48it/s]
epoch: 16, loss: 0.552
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 141.22it/s]
epoch: 17, loss: 0.5253
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 141.17it/s]
epoch: 18, loss: 0.5013
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 140.51it/s]
epoch: 19, loss: 0.4797
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 138.77it/s]
epoch: 20, loss: 0.4599
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 138.70it/s]
epoch: 21, loss: 0.4419
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 141.35it/s]
epoch: 22, loss: 0.4253
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 141.41it/s]
epoch: 23, loss: 0.4101
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 140.79it/s]
epoch: 24, loss: 0.396
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 138.71it/s]
epoch: 25, loss: 0.3829
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 136.03it/s]
epoch: 26, loss: 0.3707
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 137.74it/s]
epoch: 27, loss: 0.3594
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 133.11it/s]
epoch: 28, loss: 0.3488
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 130.95it/s]
epoch: 29, loss: 0.339
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 119.88it/s]
epoch: 30, loss: 0.3298
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 131.96it/s]
epoch: 31, loss: 0.3212
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 138.59it/s]
epoch: 32, loss: 0.313
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 126.56it/s]
epoch: 33, loss: 0.3054
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 133.89it/s]
epoch: 34, loss: 0.2981
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 121.12it/s]
epoch: 35, loss: 0.2913
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 134.69it/s]
epoch: 36, loss: 0.2848
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 138.86it/s]
epoch: 37, loss: 0.2786
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 118.93it/s]
epoch: 38, loss: 0.2727
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 130.00it/s]
epoch: 39, loss: 0.2672
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 138.42it/s]
epoch: 40, loss: 0.2619
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 130.89it/s]
epoch: 41, loss: 0.2569
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 141.59it/s]
epoch: 42, loss: 0.2521
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 141.46it/s]
epoch: 43, loss: 0.2475
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 141.19it/s]
epoch: 44, loss: 0.2431
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 142.23it/s]
epoch: 45, loss: 0.239
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 143.47it/s]
epoch: 46, loss: 0.2349
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 142.62it/s]
epoch: 47, loss: 0.2311
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 142.89it/s]
epoch: 48, loss: 0.2274
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 142.46it/s]
epoch: 49, loss: 0.2238
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 141.45it/s]
epoch: 50, loss: 0.2204
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 143.66it/s]
epoch: 51, loss: 0.2172
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 142.24it/s]
epoch: 52, loss: 0.214
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 139.68it/s]
epoch: 53, loss: 0.2109
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 142.50it/s]
epoch: 54, loss: 0.208
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 140.14it/s]
epoch: 55, loss: 0.2052
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 140.82it/s]
epoch: 56, loss: 0.2025
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 140.46it/s]
epoch: 57, loss: 0.1998
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 141.85it/s]
epoch: 58, loss: 0.1973
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 141.80it/s]
epoch: 59, loss: 0.1948
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 142.33it/s]
epoch: 60, loss: 0.1924
Finished Training

Testing the network on the test data

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 259.54it/s]
epoch: 4000, loss: 0.0375



with mse

(uri) rickbook@rickbook:~/document/neuro/project-abns/project-abns$ python experiments/predict_signal_from_signal.py 
Opening raw data file /home/rickbook/mne_data/MNE-multimodal-data/multimodal_raw.fif...
    Read a total of 7 projection items:
        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle
        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle
    Range : 183600 ... 576599 =    305.687 ...   960.014 secs
Ready.
100%|████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:00<00:00, 16010.35it/s]

#################################
data shape:  torch.Size([4000, 317, 10])
label shape:  torch.Size([4000, 317, 10])
#################################

#################################
sample train:  3200
sample test:  800




#################################
sample train shape:  3200
sample test shape:  800



cuda:0
Net(
  (te): TransformerEncoderLayer(
    (attn): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=10, out_features=10, bias=True)
    )
    (linear1): Linear(in_features=10, out_features=60, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (linear2): Linear(in_features=60, out_features=10, bias=True)
    (norm1): LayerNorm((10,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((10,), eps=1e-05, elementwise_affine=True)
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (activation): GELU(approximate='none')
  )
  (mlp): MLP(
    (linear1): Linear(in_features=10, out_features=300, bias=True)
    (linear2): Linear(in_features=300, out_features=10, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (activation): GELU(approximate='none')
  )
)
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 48.92it/s]
epoch: 1, loss: 0.9859
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 133.78it/s]
epoch: 2, loss: 0.8418
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 132.16it/s]
epoch: 3, loss: 0.7806
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 134.79it/s]
epoch: 4, loss: 0.7447
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 140.48it/s]
epoch: 5, loss: 0.7207
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 138.25it/s]
epoch: 6, loss: 0.7035
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 137.88it/s]
epoch: 7, loss: 0.6905
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 134.31it/s]
epoch: 8, loss: 0.6803
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 130.59it/s]
epoch: 9, loss: 0.672
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 136.43it/s]
epoch: 10, loss: 0.6652
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 136.66it/s]
epoch: 11, loss: 0.6595
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 138.49it/s]
epoch: 12, loss: 0.6545
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 138.40it/s]
epoch: 13, loss: 0.6502
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 134.46it/s]
epoch: 14, loss: 0.6462
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 131.96it/s]
epoch: 15, loss: 0.6425
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 133.56it/s]
epoch: 16, loss: 0.6388
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 140.87it/s]
epoch: 17, loss: 0.6351
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 137.71it/s]
epoch: 18, loss: 0.6314
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 137.33it/s]
epoch: 19, loss: 0.6277
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 133.90it/s]
epoch: 20, loss: 0.6238
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 133.55it/s]
epoch: 21, loss: 0.6198
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 136.92it/s]
epoch: 22, loss: 0.616
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 139.25it/s]
epoch: 23, loss: 0.6124
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 133.35it/s]
epoch: 24, loss: 0.6089
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 133.20it/s]
epoch: 25, loss: 0.6055
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 130.11it/s]
epoch: 26, loss: 0.6025
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 132.42it/s]
epoch: 27, loss: 0.5995
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 134.36it/s]
epoch: 28, loss: 0.5965
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 130.22it/s]
epoch: 29, loss: 0.5937
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 130.69it/s]
epoch: 30, loss: 0.5908
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 129.24it/s]
epoch: 31, loss: 0.5881
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 130.03it/s]
epoch: 32, loss: 0.5854
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 130.95it/s]
epoch: 33, loss: 0.5828
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 130.51it/s]
epoch: 34, loss: 0.5805
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 133.39it/s]
epoch: 35, loss: 0.578
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 129.17it/s]
epoch: 36, loss: 0.5754
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 128.06it/s]
epoch: 37, loss: 0.5728
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 128.59it/s]
epoch: 38, loss: 0.5706
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 129.67it/s]
epoch: 39, loss: 0.5685
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 131.72it/s]
epoch: 40, loss: 0.5661
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 131.24it/s]
epoch: 41, loss: 0.5638
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 129.64it/s]
epoch: 42, loss: 0.562
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 129.00it/s]
epoch: 43, loss: 0.5598
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 128.68it/s]
epoch: 44, loss: 0.5576
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 128.89it/s]
epoch: 45, loss: 0.5554
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 130.66it/s]
epoch: 46, loss: 0.5534
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 129.59it/s]
epoch: 47, loss: 0.5514
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 139.73it/s]
epoch: 48, loss: 0.5494
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 128.77it/s]
epoch: 49, loss: 0.5475
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 131.67it/s]
epoch: 50, loss: 0.5458
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 129.78it/s]
epoch: 51, loss: 0.544
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 131.06it/s]
epoch: 52, loss: 0.5423
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 130.19it/s]
epoch: 53, loss: 0.5405
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 129.60it/s]
epoch: 54, loss: 0.5389
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 132.33it/s]
epoch: 55, loss: 0.5373
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 128.91it/s]
epoch: 56, loss: 0.5358
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 131.19it/s]
epoch: 57, loss: 0.5343
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 129.57it/s]
epoch: 58, loss: 0.533
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 129.47it/s]
epoch: 59, loss: 0.5317
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 130.56it/s]
epoch: 60, loss: 0.5304
Finished Training

Testing the network on the test data

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 259.83it/s]
epoch: 4000, loss: 0.4125




window = 50

(uri) rickbook@rickbook:~/document/neuro/project-abns/project-abns$ python experiments/predict_signal_from_signal.py 
Opening raw data file /home/rickbook/mne_data/MNE-multimodal-data/multimodal_raw.fif...
    Read a total of 7 projection items:
        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle
        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle
    Range : 183600 ... 576599 =    305.687 ...   960.014 secs
Ready.
100%|████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:00<00:00, 10958.88it/s]

#################################
data shape:  torch.Size([4000, 317, 50])
label shape:  torch.Size([4000, 317, 50])
#################################

#################################
sample train:  3200
sample test:  800




#################################
sample train shape:  3200
sample test shape:  800



cuda:0
Net(
  (te): TransformerEncoderLayer(
    (attn): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=50, out_features=50, bias=True)
    )
    (linear1): Linear(in_features=50, out_features=60, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (linear2): Linear(in_features=60, out_features=50, bias=True)
    (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (activation): GELU(approximate='none')
  )
  (mlp): MLP(
    (linear1): Linear(in_features=50, out_features=300, bias=True)
    (linear2): Linear(in_features=300, out_features=50, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (activation): GELU(approximate='none')
  )
)
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 20.24it/s]
epoch: 1, loss: 7.7239
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.01it/s]
epoch: 2, loss: 5.3427
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.19it/s]
epoch: 3, loss: 4.259
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.19it/s]
epoch: 4, loss: 3.5998
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 44.99it/s]
epoch: 5, loss: 3.1399
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.24it/s]
epoch: 6, loss: 2.8013
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 44.71it/s]
epoch: 7, loss: 2.541
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 44.35it/s]
epoch: 8, loss: 2.3339
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 44.21it/s]
epoch: 9, loss: 2.1642
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 44.56it/s]
epoch: 10, loss: 2.0214
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 44.13it/s]
epoch: 11, loss: 1.899
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 44.04it/s]
epoch: 12, loss: 1.7922
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 44.98it/s]
epoch: 13, loss: 1.698
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 44.37it/s]
epoch: 14, loss: 1.6139
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 44.63it/s]
epoch: 15, loss: 1.5382
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 44.12it/s]
epoch: 16, loss: 1.4695
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.00it/s]
epoch: 17, loss: 1.4068
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 46.34it/s]
epoch: 18, loss: 1.3494
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.47it/s]
epoch: 19, loss: 1.2965
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.32it/s]
epoch: 20, loss: 1.2477
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.95it/s]
epoch: 21, loss: 1.2025
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 44.46it/s]
epoch: 22, loss: 1.1605
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.73it/s]
epoch: 23, loss: 1.1214
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.50it/s]
epoch: 24, loss: 1.085
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.78it/s]
epoch: 25, loss: 1.0509
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.14it/s]
epoch: 26, loss: 1.019
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 44.13it/s]
epoch: 27, loss: 0.9892
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 46.09it/s]
epoch: 28, loss: 0.9611
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.29it/s]
epoch: 29, loss: 0.9347
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.46it/s]
epoch: 30, loss: 0.9098
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 46.14it/s]
epoch: 31, loss: 0.8864
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.77it/s]
epoch: 32, loss: 0.8642
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.90it/s]
epoch: 33, loss: 0.8432
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.32it/s]
epoch: 34, loss: 0.8234
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.00it/s]
epoch: 35, loss: 0.8045
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.16it/s]
epoch: 36, loss: 0.7867
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.18it/s]
epoch: 37, loss: 0.7696
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.93it/s]
epoch: 38, loss: 0.7534
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.98it/s]
epoch: 39, loss: 0.738
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.69it/s]
epoch: 40, loss: 0.7233
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.76it/s]
epoch: 41, loss: 0.7092
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.73it/s]
epoch: 42, loss: 0.6958
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 44.73it/s]
epoch: 43, loss: 0.6829
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.40it/s]
epoch: 44, loss: 0.6706
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.86it/s]
epoch: 45, loss: 0.6588
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.90it/s]
epoch: 46, loss: 0.6475
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 44.42it/s]
epoch: 47, loss: 0.6366
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.77it/s]
epoch: 48, loss: 0.6261
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.83it/s]
epoch: 49, loss: 0.6161
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.66it/s]
epoch: 50, loss: 0.6064
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.47it/s]
epoch: 51, loss: 0.5971
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.76it/s]
epoch: 52, loss: 0.5881
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.21it/s]
epoch: 53, loss: 0.5795
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.22it/s]
epoch: 54, loss: 0.5711
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.65it/s]
epoch: 55, loss: 0.563
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.66it/s]
epoch: 56, loss: 0.5552
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.87it/s]
epoch: 57, loss: 0.5477
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.47it/s]
epoch: 58, loss: 0.5404
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.83it/s]
epoch: 59, loss: 0.5334
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 45.64it/s]
epoch: 60, loss: 0.5266
Finished Training

Testing the network on the test data

100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 87.51it/s]
epoch: 4000, loss: 0.147
'''

