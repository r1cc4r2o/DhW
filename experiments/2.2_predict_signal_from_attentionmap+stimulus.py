""" Here we try to predict the next signal from the attention map 
    gerenated by the previous signal+stimulus.

"""

import mne
import glob
import matplotlib
import matplotlib.pyplot as plt

import gc
gc.collect()

matplotlib.use('Qt5Agg')


""" Code to read the data and convert EDF into FIF format. """

# files_name = [f.split('/')[10].split('.')[0] for f in [file for file in glob.glob('/Users/riccardotedoldi/Desktop/ais/I/sem2/abns/project/eeg-during-mental-arithmetic-tasks-1.0.0/*.edf')]]
# path_files  = glob.glob('/Users/riccardotedoldi/Desktop/ais/I/sem2/abns/project/eeg-during-mental-arithmetic-tasks-1.0.0/*.edf')

# # read data
# # convert to FIF
# for name, file in zip(files_name, path_files):
#     raw = mne.io.read_raw_edf(file) 
#     # save as FIF
#     raw.save(f'/Users/riccardotedoldi/Desktop/ais/I/sem2/abns/project/eeg-during-mental-arithmetic-tasks-1.0.0/{name}.fif')
    


""" Code to read the data and plot it. """
import numpy as np

# read data eeg
import mne
from mne.datasets import multimodal

import glob
import os

import matplotlib.pyplot as plt

import math

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

from tqdm import tqdm

fname_raw = os.path.join(multimodal.data_path(), 'multimodal_raw.fif')

raw = mne.io.read_raw_fif(fname_raw)


d = raw.get_data()


number_samples = 3000

data = []
label = []

window = 10
batch = 120

min = 0
max = window

for _ in tqdm(range(number_samples)):
    data.append(torch.Tensor(d[:,min:max]) @ torch.Tensor(d[:,min:max]).permute(1,0))
    min = min + window
    max = max + window 
    label.append(torch.Tensor(d[:,min:max]))

# delete the raw data
del d

t_sample = torch.Tensor(number_samples, data[0].shape[0], data[0].shape[1])
t_label = torch.Tensor(number_samples, label[0].shape[0], label[0].shape[1])

for i in range(number_samples):
    t_sample[i] = data[i]
    t_label[i] = label[i]
    
# add cls token
cls_ = torch.zeros(number_samples, 1, data[0].shape[1])

t_sample = torch.cat((cls_, t_sample), dim=1)

cls_ = torch.zeros(number_samples, 1, label[0].shape[1])

t_label = torch.cat((cls_, t_label), dim=1)

del cls_

print()
print('#'*len('data shape: '+str(t_sample[0].shape)))
print('data shape: ', t_sample.shape)
print('label shape: ', t_label.shape)
print('#'*len('data shape: '+str(t_sample[0].shape)))

s_train = int(number_samples*0.8)
s_test = number_samples - s_train

print()
print('#'*len('data shape: '+str(t_sample[0].shape)))
print('sample train: ', s_train)
print('sample test: ', s_test)
print()
print()
print()

data = torch.utils.data.TensorDataset(t_sample, t_label)
training_samples, validation_samples = torch.utils.data.random_split(data, [s_train, s_test])

print()
print('#'*len('data shape: '+str(t_sample[0].shape)))
print('sample train shape: ', len(training_samples))
print('sample test shape: ', len(validation_samples))
print()
print()
print()

train = torch.utils.data.DataLoader(training_samples, batch_size=batch, shuffle=True)
val = torch.utils.data.DataLoader(validation_samples, batch_size=batch, shuffle=False)

print('data loaded')


# Example of MultiHeadAttention
def MultiHeadAttention(query, key, value, mask=None, dropout=None):
    d_k = query.size(-1)
    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)
    if mask is not None:
        scores = scores.masked_fill(mask == 0, -1e9)
    p_attn = F.softmax(scores, dim = -1)
    if dropout is not None:
        p_attn = dropout(p_attn)
    return torch.matmul(p_attn, value), p_attn



# result, attn_map = MultiHeadAttention(t_sample, t_sample, t_label)

# print()
# print('#'*len('data shape: '+str(t_sample[0].shape)))
# print('result shape: ', result.shape)
# print('attn_map shape: ', attn_map.shape)
# print('#'*len('data shape: '+str(t_sample[0].shape)))


# plt.imshow(attn_map[0].detach().numpy())



class TransformerEncoderLayer(nn.Module):
    def __init__(self, dim_emb, nhead: int = 2, dim_feedforward: int = 50, dropout: float =0.1, activation = nn.GELU):
        super(TransformerEncoderLayer, self).__init__()
        
        self.attn = nn.MultiheadAttention(dim_emb, nhead, dropout=dropout)
        
        # Implementation of Feedforward model
        self.linear1 = nn.Linear(dim_emb, dim_feedforward)
        self.dropout = nn.Dropout(dropout)
        self.linear2 = nn.Linear(dim_feedforward, dim_emb)

        self.norm1 = nn.LayerNorm(dim_emb)
        self.norm2 = nn.LayerNorm(dim_emb)
        
        self.dropout1 = nn.Dropout(dropout)
        self.dropout2 = nn.Dropout(dropout)

        self.activation = activation()

    def forward(self, data, src_mask=None, src_key_padding_mask=None):
        
        # MultiHeadAttention
        x = self.attn(data, data, data, attn_mask=src_mask, key_padding_mask=src_key_padding_mask)[0]
        
        # add & norm
        x = data + self.dropout1(x)
        x = self.norm1(x)
        
        # Implementation of Feedforward model
        x1 = self.linear2(self.dropout(self.activation(self.linear1(x))))
        
        # add & norm
        x = x + self.dropout2(x1)
        x = self.norm2(x)
        
        return x        

class MLP(nn.Module):
    def __init__(self, dim_emb, out_dim, dim_feedforward: int = 200, dropout: float =0.1, activation = nn.GELU):
        super(MLP, self).__init__()
        
        # Implementation of Feedforward model
        self.linear1 = nn.Linear(dim_emb, dim_feedforward)
        self.linear2 = nn.Linear(dim_feedforward, out_dim)
        
        self.dropout = nn.Dropout(dropout)
        self.activation = activation()

    def forward(self, x):
        
        x = self.linear2(self.dropout(self.activation(self.linear1(x))))    
            
        return x

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
    
        self.te = TransformerEncoderLayer(t_sample.shape[2])
        # i make the output dim equal to the dimesion of the label
        self.mlp = MLP(t_sample.shape[2], label[0].shape[1])
        
    def forward(self, data):
        x = self.te(data)
        x = self.mlp(x[:,:x.shape[1]-1])
        return x


# nn.CrossEntropyLoss()
def se_loss(y_pred, y_true):
    squared_error = abs(y_pred - y_true)
    # squared_error = (y_pred - y_true)**2
    loss = torch.sum(squared_error)
    return loss

def training(net, train, optimizer, criterion = se_loss, epochs: int = 30):
    samples = 0.0
    cumulative_loss = 0.0
    cumulative_accuracy = 0.0

    # set the network in the training mode
    net.train()

    for i in range(epochs):
        for data, label in tqdm(train):
            data, label = data.to(device), label.to(device)

            # forward + backward + optimize
            outputs = net(data)
            loss = criterion(outputs, label[:,:label.shape[1]-1])
            loss.backward()
            optimizer.step()
        
            # zero the parameter gradients
            optimizer.zero_grad()
        
            # calculate the loss and accuracy
            samples += len(data)
            cumulative_loss += loss.item()
            # cumulative_accuracy += (outputs.argmax(1) == label).sum().item()
        
        # print statistics
        # print('epoch: %d, loss: %.3f, accuracy: %.3f' % (i + 1, cumulative_loss / samples, cumulative_accuracy / samples))
        print(f'epoch: {i + 1}, loss: {round(cumulative_loss / samples,4)}')
        
def test(net, test, criterion = se_loss):
    samples = 0.0
    cumulative_loss = 0.0
    cumulative_accuracy = 0.0

    # set the network in the training mode
    net.eval()

    # disable gradient calculation
    with torch.no_grad():
        for data, label in tqdm(test):
            data, label = data.to(device), label.to(device)
        
            # forward + backward + optimize
            outputs = net(data)
            loss = criterion(outputs, label[:,:label.shape[1]-1])
        
            # calculate the loss and accuracy
            samples += len(data)
            cumulative_loss += loss.item()
            # cumulative_accuracy += (outputs.argmax(1) == label).sum().item()
        
        # print statistics
        # print('epoch: %d, loss: %.3f, accuracy: %.3f' % (i + 1, cumulative_loss / samples, cumulative_accuracy / samples))
        print(f'test loss: {round(cumulative_loss / samples,4)}')
            
            


device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
# print(device)

net = Net().cuda()
print(net)

training(net, train, optimizer = optim.AdamW(net.parameters(), lr=0.001))
print('Finished Training')
print()
print('Testing the network on the test data')
print()
test(net, val)
    



# # meg sensors
# [10,10,10,10,10,10,10,10] image of a monkey
# [10,10,10,10,10,10,10,10]
# [10,10,10,10,10,10,10,10]
# [10,10,10,10,10,10,10,10]
# [10,10,10,10,10,10,10,10]
# [10,10,10,10,10,10,10,10]
# [10,10,10,10,10,10,10,10]
# [10,10,10,10,10,10,10,10]
# [10,10,10,10,10,10,10,10]
# [10,10,10,10,10,10,10,10]
# [10,10,10,10,10,10,10,10]
# [10,10,10,10,10,10,10,10]
# [10,10,10,10,10,10,10,10]
# # eeg sensors
# [10,10,10,10,10,10,10,10]
# [10,10,10,10,10,10,10,10]
# [10,10,10,10,10,10,10,10]
# [10,10,10,10,10,10,10,10]
# [10,10,10,10,10,10,10,10]
# [10,10,10,10,10,10,10,10]
# [10,10,10,10,10,10,10,10]
# [10,10,10,10,10,10,10,10]
# [10,10,10,10,10,10,10,10]
# [10,10,10,10,10,10,10,10]
# [10,10,10,10,10,10,10,10]
# [10,10,10,10,10,10,10,10]
# [10,10,10,10,10,10,10,10]
# # stimulus
# [10,10,10,10,10,10,10,10]
# [10,10,10,10,10,10,10,10]
# [10,10,10,10,10,10,10,10]

''' bach size 64
(uri) rickbook@rickbook:~/document/neuro/project-abns/project-abns$ python experiments/predict_signal_from_attentionmap+stimulus.py 
Opening raw data file /home/rickbook/mne_data/MNE-multimodal-data/multimodal_raw.fif...
    Read a total of 7 projection items:
        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle
        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle
    Range : 183600 ... 576599 =    305.687 ...   960.014 secs
Ready.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3000/3000 [00:00<00:00, 6095.43it/s]

##################################
data shape:  torch.Size([3000, 317, 316])
label shape:  torch.Size([3000, 317, 10])
##################################

##################################
sample train:  2400
sample test:  600




##################################
sample train shape:  2400
sample test shape:  600



data loaded
Net(
  (te): TransformerEncoderLayer(
    (attn): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=316, out_features=316, bias=True)
    )
    (linear1): Linear(in_features=316, out_features=100, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (linear2): Linear(in_features=100, out_features=316, bias=True)
    (norm1): LayerNorm((316,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((316,), eps=1e-05, elementwise_affine=True)
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (activation): GELU(approximate='none')
  )
  (mlp): MLP(
    (linear1): Linear(in_features=316, out_features=10, bias=True)
    (linear2): Linear(in_features=10, out_features=10, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (activation): GELU(approximate='none')
  )
)
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 21.33it/s]
epoch: 1, loss: 480.3891
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.69it/s]
epoch: 2, loss: 402.157
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.31it/s]
epoch: 3, loss: 339.3959
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.15it/s]
epoch: 4, loss: 288.3508
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.41it/s]
epoch: 5, loss: 247.0755
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.10it/s]
epoch: 6, loss: 214.6744
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.21it/s]
epoch: 7, loss: 189.3007
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.11it/s]
epoch: 8, loss: 169.754
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.53it/s]
epoch: 9, loss: 154.2403
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.80it/s]
epoch: 10, loss: 141.5204
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.78it/s]
epoch: 11, loss: 130.8666
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.91it/s]
epoch: 12, loss: 121.8055
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 32.09it/s]
epoch: 13, loss: 114.1771
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.45it/s]
epoch: 14, loss: 107.4468
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.71it/s]
epoch: 15, loss: 101.573
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.62it/s]
epoch: 16, loss: 96.3918
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.60it/s]
epoch: 17, loss: 91.7711
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.62it/s]
epoch: 18, loss: 87.6323
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.75it/s]
epoch: 19, loss: 83.8802
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.83it/s]
epoch: 20, loss: 80.4823
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 32.19it/s]
epoch: 21, loss: 77.3769
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 32.38it/s]
epoch: 22, loss: 74.5344
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 32.05it/s]
epoch: 23, loss: 71.9846
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.99it/s]
epoch: 24, loss: 69.5999
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 32.27it/s]
epoch: 25, loss: 67.3391
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 32.15it/s]
epoch: 26, loss: 65.2338
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 32.14it/s]
epoch: 27, loss: 63.2729
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.57it/s]
epoch: 28, loss: 61.4387
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.68it/s]
epoch: 29, loss: 59.7162
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.67it/s]
epoch: 30, loss: 58.0965
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.68it/s]
epoch: 31, loss: 56.5722
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.41it/s]
epoch: 32, loss: 55.1352
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.56it/s]
epoch: 33, loss: 53.7846
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.64it/s]
epoch: 34, loss: 52.5037
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.47it/s]
epoch: 35, loss: 51.2798
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.46it/s]
epoch: 36, loss: 50.107
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.84it/s]
epoch: 37, loss: 48.9898
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.49it/s]
epoch: 38, loss: 47.9294
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.97it/s]
epoch: 39, loss: 46.9148
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:01<00:00, 31.69it/s]
epoch: 40, loss: 45.9472
Finished Training

Testing the network on the test data

100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 65.83it/s]
test loss: 5.9326

'''


''' bach size 120 epoch 40 lr 0.0001

uri) rickbook@rickbook:~/document/neuro/project-abns/project-abns$ python experiments/predict_signal_from_attentionmap+stimulus.py 
Opening raw data file /home/rickbook/mne_data/MNE-multimodal-data/multimodal_raw.fif...
    Read a total of 7 projection items:
        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle
        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle
    Range : 183600 ... 576599 =    305.687 ...   960.014 secs
Ready.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3000/3000 [00:00<00:00, 6496.71it/s]

##################################
data shape:  torch.Size([3000, 317, 316])
label shape:  torch.Size([3000, 317, 10])
##################################

##################################
sample train:  2400
sample test:  600




##################################
sample train shape:  2400
sample test shape:  600



data loaded
Net(
  (te): TransformerEncoderLayer(
    (attn): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=316, out_features=316, bias=True)
    )
    (linear1): Linear(in_features=316, out_features=100, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (linear2): Linear(in_features=100, out_features=316, bias=True)
    (norm1): LayerNorm((316,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((316,), eps=1e-05, elementwise_affine=True)
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (activation): GELU(approximate='none')
  )
  (mlp): MLP(
    (linear1): Linear(in_features=316, out_features=10, bias=True)
    (linear2): Linear(in_features=10, out_features=10, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (activation): GELU(approximate='none')
  )
)
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 11.44it/s]
epoch: 1, loss: 823.6948
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.53it/s]
epoch: 2, loss: 532.1149
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.41it/s]
epoch: 3, loss: 407.4452
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.49it/s]
epoch: 4, loss: 333.8317
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.25it/s]
epoch: 5, loss: 286.8665
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.36it/s]
epoch: 6, loss: 254.0858
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.61it/s]
epoch: 7, loss: 229.4472
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.96it/s]
epoch: 8, loss: 209.9872
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.70it/s]
epoch: 9, loss: 194.099
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 17.00it/s]
epoch: 10, loss: 180.7589
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.95it/s]
epoch: 11, loss: 169.389
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.91it/s]
epoch: 12, loss: 159.4979
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.95it/s]
epoch: 13, loss: 150.7878
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.81it/s]
epoch: 14, loss: 143.0181
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.85it/s]
epoch: 15, loss: 136.0448
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.86it/s]
epoch: 16, loss: 129.7324
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.87it/s]
epoch: 17, loss: 123.9932
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.94it/s]
epoch: 18, loss: 118.7252
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.89it/s]
epoch: 19, loss: 113.8792
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.60it/s]
epoch: 20, loss: 109.3964
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 14.96it/s]
epoch: 21, loss: 105.249
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.25it/s]
epoch: 22, loss: 101.4019
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.79it/s]
epoch: 23, loss: 97.8268
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.27it/s]
epoch: 24, loss: 94.495
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.74it/s]
epoch: 25, loss: 91.3877
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.92it/s]
epoch: 26, loss: 88.4874
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.89it/s]
epoch: 27, loss: 85.7816
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.93it/s]
epoch: 28, loss: 83.2492
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.91it/s]
epoch: 29, loss: 80.8751
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.86it/s]
epoch: 30, loss: 78.6435
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.90it/s]
epoch: 31, loss: 76.5419
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.83it/s]
epoch: 32, loss: 74.5595
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.86it/s]
epoch: 33, loss: 72.6837
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.93it/s]
epoch: 34, loss: 70.9066
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.86it/s]
epoch: 35, loss: 69.2225
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.93it/s]
epoch: 36, loss: 67.6224
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.78it/s]
epoch: 37, loss: 66.0984
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.92it/s]
epoch: 38, loss: 64.6447
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.71it/s]
epoch: 39, loss: 63.2578
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 16.85it/s]
epoch: 40, loss: 61.9318
Finished Training

Testing the network on the test data

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 34.70it/s]
test loss: 5.361

'''


''' the last configuration of the network
(uri) rickbook@rickbook:~/document/neuro/project-abns/project-abns$ python experiments/predict_signal_from_attentionmap+stimulus.py 
Opening raw data file /home/rickbook/mne_data/MNE-multimodal-data/multimodal_raw.fif...
    Read a total of 7 projection items:
        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle
        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle
        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle
    Range : 183600 ... 576599 =    305.687 ...   960.014 secs
Ready.
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3000/3000 [00:00<00:00, 6089.85it/s]

##################################
data shape:  torch.Size([3000, 317, 316])
label shape:  torch.Size([3000, 317, 10])
##################################

##################################
sample train:  2400
sample test:  600




##################################
sample train shape:  2400
sample test shape:  600



data loaded
Net(
  (te): TransformerEncoderLayer(
    (attn): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=316, out_features=316, bias=True)
    )
    (linear1): Linear(in_features=316, out_features=50, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (linear2): Linear(in_features=50, out_features=316, bias=True)
    (norm1): LayerNorm((316,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((316,), eps=1e-05, elementwise_affine=True)
    (dropout1): Dropout(p=0.1, inplace=False)
    (dropout2): Dropout(p=0.1, inplace=False)
    (activation): GELU(approximate='none')
  )
  (mlp): MLP(
    (linear1): Linear(in_features=316, out_features=200, bias=True)
    (linear2): Linear(in_features=200, out_features=10, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (activation): GELU(approximate='none')
  )
)
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 11.08it/s]
epoch: 1, loss: 353.2059
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.85it/s]
epoch: 2, loss: 216.8472
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.81it/s]
epoch: 3, loss: 166.0534
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.74it/s]
epoch: 4, loss: 138.6712
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.72it/s]
epoch: 5, loss: 120.8767
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.87it/s]
epoch: 6, loss: 108.0557
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.83it/s]
epoch: 7, loss: 98.1941
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.87it/s]
epoch: 8, loss: 90.2713
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.77it/s]
epoch: 9, loss: 83.6895
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.78it/s]
epoch: 10, loss: 78.0821
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.82it/s]
epoch: 11, loss: 73.2274
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.73it/s]
epoch: 12, loss: 68.9686
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.97it/s]
epoch: 13, loss: 65.192
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.81it/s]
epoch: 14, loss: 61.822
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.77it/s]
epoch: 15, loss: 58.7933
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.79it/s]
epoch: 16, loss: 56.0522
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.69it/s]
epoch: 17, loss: 53.5673
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.78it/s]
epoch: 18, loss: 51.2886
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.79it/s]
epoch: 19, loss: 49.2028
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.83it/s]
epoch: 20, loss: 47.2779
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.74it/s]
epoch: 21, loss: 45.4984
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.67it/s]
epoch: 22, loss: 43.8504
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.78it/s]
epoch: 23, loss: 42.315
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.72it/s]
epoch: 24, loss: 40.882
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.82it/s]
epoch: 25, loss: 39.5404
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.76it/s]
epoch: 26, loss: 38.2819
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.78it/s]
epoch: 27, loss: 37.1006
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.78it/s]
epoch: 28, loss: 35.9876
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.59it/s]
epoch: 29, loss: 34.938
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:01<00:00, 15.64it/s]
epoch: 30, loss: 33.9457
Finished Training

Testing the network on the test data

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 32.10it/s]
test loss: 3.5595

'''



