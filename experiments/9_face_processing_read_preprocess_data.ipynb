{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ekg: ['EEG063', 'EEG064']\n",
      "heog: ['EEG061']\n",
      "veog: ['EEG062']\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n",
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Estimated head radius (1.1 cm) is below the 3rd percentile for infant head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['famous_new', 'famous_second_early', 'famous_second_late', 'scrambled_new', 'scrambled_second_early', 'scrambled_second_late', 'unfamiliar_new', 'unfamiliar_second_early', 'unfamiliar_second_late']\n",
      "Not setting metadata\n",
      "584 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 584 events and 189 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Setting up band-pass filter from 4 - 80 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 80.00 Hz\n",
      "- Upper transition bandwidth: 20.00 Hz (-6 dB cutoff frequency: 90.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:126: RuntimeWarning: filter_length (413) is longer than the signal (189), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  epochs.filter(4, 80)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 43216 out of 43216 | elapsed:    9.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-002.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ekg: ['EEG063', 'EEG064']\n",
      "heog: ['EEG061']\n",
      "veog: ['EEG062']\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n",
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Estimated head radius (1.1 cm) is below the 3rd percentile for infant head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['famous_new', 'famous_second_early', 'famous_second_late', 'scrambled_new', 'scrambled_second_early', 'scrambled_second_late', 'unfamiliar_new', 'unfamiliar_second_early', 'unfamiliar_second_late']\n",
      "Not setting metadata\n",
      "860 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 860 events and 189 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Setting up band-pass filter from 4 - 80 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 80.00 Hz\n",
      "- Upper transition bandwidth: 20.00 Hz (-6 dB cutoff frequency: 90.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:126: RuntimeWarning: filter_length (413) is longer than the signal (189), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  epochs.filter(4, 80)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 63640 out of 63640 | elapsed:   13.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-002.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-003.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ekg: ['EEG063', 'EEG064']\n",
      "heog: ['EEG061']\n",
      "veog: ['EEG062']\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n",
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Estimated head radius (1.1 cm) is below the 3rd percentile for infant head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['famous_new', 'famous_second_early', 'famous_second_late', 'scrambled_new', 'scrambled_second_early', 'scrambled_second_late', 'unfamiliar_new', 'unfamiliar_second_early', 'unfamiliar_second_late']\n",
      "Not setting metadata\n",
      "794 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 794 events and 189 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Setting up band-pass filter from 4 - 80 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 80.00 Hz\n",
      "- Upper transition bandwidth: 20.00 Hz (-6 dB cutoff frequency: 90.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:126: RuntimeWarning: filter_length (413) is longer than the signal (189), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  epochs.filter(4, 80)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 58756 out of 58756 | elapsed:   11.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-002.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-003.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-004.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ekg: ['EEG063', 'EEG064']\n",
      "heog: ['EEG061']\n",
      "veog: ['EEG062']\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n",
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Estimated head radius (1.1 cm) is below the 3rd percentile for infant head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['famous_new', 'famous_second_early', 'famous_second_late', 'scrambled_new', 'scrambled_second_early', 'scrambled_second_late', 'unfamiliar_new', 'unfamiliar_second_early', 'unfamiliar_second_late']\n",
      "Not setting metadata\n",
      "805 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 805 events and 189 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Setting up band-pass filter from 4 - 80 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 80.00 Hz\n",
      "- Upper transition bandwidth: 20.00 Hz (-6 dB cutoff frequency: 90.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:126: RuntimeWarning: filter_length (413) is longer than the signal (189), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  epochs.filter(4, 80)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 59570 out of 59570 | elapsed:   11.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-002.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-003.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-004.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-005.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ekg: ['EEG063', 'EEG064']\n",
      "heog: ['EEG061']\n",
      "veog: ['EEG062']\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n",
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Estimated head radius (1.1 cm) is below the 3rd percentile for infant head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['famous_new', 'famous_second_early', 'famous_second_late', 'scrambled_new', 'scrambled_second_early', 'scrambled_second_late', 'unfamiliar_new', 'unfamiliar_second_early', 'unfamiliar_second_late']\n",
      "Not setting metadata\n",
      "883 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 883 events and 189 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Setting up band-pass filter from 4 - 80 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 80.00 Hz\n",
      "- Upper transition bandwidth: 20.00 Hz (-6 dB cutoff frequency: 90.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:126: RuntimeWarning: filter_length (413) is longer than the signal (189), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  epochs.filter(4, 80)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 65342 out of 65342 | elapsed:   11.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-002.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-003.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-004.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-005.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-006.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ekg: ['EEG063', 'EEG064']\n",
      "heog: ['EEG061']\n",
      "veog: ['EEG062']\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n",
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Estimated head radius (1.1 cm) is below the 3rd percentile for infant head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['famous_new', 'famous_second_early', 'famous_second_late', 'scrambled_new', 'scrambled_second_early', 'scrambled_second_late', 'unfamiliar_new', 'unfamiliar_second_early', 'unfamiliar_second_late']\n",
      "Not setting metadata\n",
      "884 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 884 events and 189 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Setting up band-pass filter from 4 - 80 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 80.00 Hz\n",
      "- Upper transition bandwidth: 20.00 Hz (-6 dB cutoff frequency: 90.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:126: RuntimeWarning: filter_length (413) is longer than the signal (189), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  epochs.filter(4, 80)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 65416 out of 65416 | elapsed:   12.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-002.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-003.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-004.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-005.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-006.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-007.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ekg: ['EEG063', 'EEG064']\n",
      "heog: ['EEG061']\n",
      "veog: ['EEG062']\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n",
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Estimated head radius (1.0 cm) is below the 3rd percentile for infant head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['famous_new', 'famous_second_early', 'famous_second_late', 'scrambled_new', 'scrambled_second_early', 'scrambled_second_late', 'unfamiliar_new', 'unfamiliar_second_early', 'unfamiliar_second_late']\n",
      "Not setting metadata\n",
      "882 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 882 events and 189 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Setting up band-pass filter from 4 - 80 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 80.00 Hz\n",
      "- Upper transition bandwidth: 20.00 Hz (-6 dB cutoff frequency: 90.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:126: RuntimeWarning: filter_length (413) is longer than the signal (189), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  epochs.filter(4, 80)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 65268 out of 65268 | elapsed:   12.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-002.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-003.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-004.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-005.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-006.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-007.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-008.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ekg: ['EEG063', 'EEG064']\n",
      "heog: ['EEG061']\n",
      "veog: ['EEG062']\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n",
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Estimated head radius (1.0 cm) is below the 3rd percentile for infant head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['famous_new', 'famous_second_early', 'famous_second_late', 'scrambled_new', 'scrambled_second_early', 'scrambled_second_late', 'unfamiliar_new', 'unfamiliar_second_early', 'unfamiliar_second_late']\n",
      "Not setting metadata\n",
      "889 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 889 events and 189 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Setting up band-pass filter from 4 - 80 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 80.00 Hz\n",
      "- Upper transition bandwidth: 20.00 Hz (-6 dB cutoff frequency: 90.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:126: RuntimeWarning: filter_length (413) is longer than the signal (189), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  epochs.filter(4, 80)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 65786 out of 65786 | elapsed:   12.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-002.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-003.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-004.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-005.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-006.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-007.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-008.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-009.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ekg: ['EEG063', 'EEG064']\n",
      "heog: ['EEG061']\n",
      "veog: ['EEG062']\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n",
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Estimated head radius (1.1 cm) is below the 3rd percentile for infant head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['famous_new', 'famous_second_early', 'famous_second_late', 'scrambled_new', 'scrambled_second_early', 'scrambled_second_late', 'unfamiliar_new', 'unfamiliar_second_early', 'unfamiliar_second_late']\n",
      "Not setting metadata\n",
      "882 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 882 events and 189 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Setting up band-pass filter from 4 - 80 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 80.00 Hz\n",
      "- Upper transition bandwidth: 20.00 Hz (-6 dB cutoff frequency: 90.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:126: RuntimeWarning: filter_length (413) is longer than the signal (189), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  epochs.filter(4, 80)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 65268 out of 65268 | elapsed:   11.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-002.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-003.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-004.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-005.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-006.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-007.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-008.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-009.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-010.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ekg: ['EEG063', 'EEG064']\n",
      "heog: ['EEG061']\n",
      "veog: ['EEG062']\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n",
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Estimated head radius (1.1 cm) is below the 3rd percentile for infant head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['famous_new', 'famous_second_early', 'famous_second_late', 'scrambled_new', 'scrambled_second_early', 'scrambled_second_late', 'unfamiliar_new', 'unfamiliar_second_early', 'unfamiliar_second_late']\n",
      "Not setting metadata\n",
      "884 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 884 events and 189 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Setting up band-pass filter from 4 - 80 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 80.00 Hz\n",
      "- Upper transition bandwidth: 20.00 Hz (-6 dB cutoff frequency: 90.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:126: RuntimeWarning: filter_length (413) is longer than the signal (189), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  epochs.filter(4, 80)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 65416 out of 65416 | elapsed:   11.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-002.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-003.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-004.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-005.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-006.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-007.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-008.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-009.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-010.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-011.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ekg: ['EEG063', 'EEG064']\n",
      "heog: ['EEG061']\n",
      "veog: ['EEG062']\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n",
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Estimated head radius (1.1 cm) is below the 3rd percentile for infant head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['famous_new', 'famous_second_early', 'famous_second_late', 'scrambled_new', 'scrambled_second_early', 'scrambled_second_late', 'unfamiliar_new', 'unfamiliar_second_early', 'unfamiliar_second_late']\n",
      "Not setting metadata\n",
      "888 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 888 events and 189 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Setting up band-pass filter from 4 - 80 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 80.00 Hz\n",
      "- Upper transition bandwidth: 20.00 Hz (-6 dB cutoff frequency: 90.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:126: RuntimeWarning: filter_length (413) is longer than the signal (189), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  epochs.filter(4, 80)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 65712 out of 65712 | elapsed:   11.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-002.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-003.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-004.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-005.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-006.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-007.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-008.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-009.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-010.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-011.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-012.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ekg: ['EEG063', 'EEG064']\n",
      "heog: ['EEG061']\n",
      "veog: ['EEG062']\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n",
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Estimated head radius (1.0 cm) is below the 3rd percentile for infant head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['famous_new', 'famous_second_early', 'famous_second_late', 'scrambled_new', 'scrambled_second_early', 'scrambled_second_late', 'unfamiliar_new', 'unfamiliar_second_early', 'unfamiliar_second_late']\n",
      "Not setting metadata\n",
      "880 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 880 events and 189 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Setting up band-pass filter from 4 - 80 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 80.00 Hz\n",
      "- Upper transition bandwidth: 20.00 Hz (-6 dB cutoff frequency: 90.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:126: RuntimeWarning: filter_length (413) is longer than the signal (189), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  epochs.filter(4, 80)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 65120 out of 65120 | elapsed:   11.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-002.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-003.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-004.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-005.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-006.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-007.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-008.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-009.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-010.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-011.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-012.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-013.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ekg: ['EEG063', 'EEG064']\n",
      "heog: ['EEG061']\n",
      "veog: ['EEG062']\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n",
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Estimated head radius (1.0 cm) is below the 3rd percentile for infant head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['famous_new', 'famous_second_early', 'famous_second_late', 'scrambled_new', 'scrambled_second_early', 'scrambled_second_late', 'unfamiliar_new', 'unfamiliar_second_early', 'unfamiliar_second_late']\n",
      "Not setting metadata\n",
      "883 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 883 events and 189 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Setting up band-pass filter from 4 - 80 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 80.00 Hz\n",
      "- Upper transition bandwidth: 20.00 Hz (-6 dB cutoff frequency: 90.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:126: RuntimeWarning: filter_length (413) is longer than the signal (189), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  epochs.filter(4, 80)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 65342 out of 65342 | elapsed:   11.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-002.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-003.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-004.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-005.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-006.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-007.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-008.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-009.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-010.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-011.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-012.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-013.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-014.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ekg: ['EEG063', 'EEG064']\n",
      "heog: ['EEG061']\n",
      "veog: ['EEG062']\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n",
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Estimated head radius (1.1 cm) is below the 3rd percentile for infant head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['famous_new', 'famous_second_early', 'famous_second_late', 'scrambled_new', 'scrambled_second_early', 'scrambled_second_late', 'unfamiliar_new', 'unfamiliar_second_early', 'unfamiliar_second_late']\n",
      "Not setting metadata\n",
      "872 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 872 events and 189 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Setting up band-pass filter from 4 - 80 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 80.00 Hz\n",
      "- Upper transition bandwidth: 20.00 Hz (-6 dB cutoff frequency: 90.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:126: RuntimeWarning: filter_length (413) is longer than the signal (189), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  epochs.filter(4, 80)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 64528 out of 64528 | elapsed:   11.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-002.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-003.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-004.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-005.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-006.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-007.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-008.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-009.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-010.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-011.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-012.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-013.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-014.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-015.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ekg: ['EEG063', 'EEG064']\n",
      "heog: ['EEG061']\n",
      "veog: ['EEG062']\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n",
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Estimated head radius (1.0 cm) is below the 3rd percentile for infant head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n",
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['famous_new', 'famous_second_early', 'famous_second_late', 'scrambled_new', 'scrambled_second_early', 'scrambled_second_late', 'unfamiliar_new', 'unfamiliar_second_early', 'unfamiliar_second_late']\n",
      "Not setting metadata\n",
      "885 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 885 events and 189 original time points ...\n",
      "0 bad epochs dropped\n",
      "Setting up band-pass filter from 4 - 80 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 80.00 Hz\n",
      "- Upper transition bandwidth: 20.00 Hz (-6 dB cutoff frequency: 90.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:126: RuntimeWarning: filter_length (413) is longer than the signal (189), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  epochs.filter(4, 80)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 65490 out of 65490 | elapsed:   11.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-002.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-003.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-004.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-005.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-006.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-007.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-008.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-009.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-010.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-011.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-012.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-013.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-014.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-015.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-016.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ekg: ['EEG063', 'EEG064']\n",
      "heog: ['EEG061']\n",
      "veog: ['EEG062']\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n",
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Estimated head radius (1.1 cm) is below the 3rd percentile for infant head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['famous_new', 'famous_second_early', 'famous_second_late', 'scrambled_new', 'scrambled_second_early', 'scrambled_second_late', 'unfamiliar_new', 'unfamiliar_second_early', 'unfamiliar_second_late']\n",
      "Not setting metadata\n",
      "883 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 883 events and 189 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Setting up band-pass filter from 4 - 80 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 80.00 Hz\n",
      "- Upper transition bandwidth: 20.00 Hz (-6 dB cutoff frequency: 90.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:126: RuntimeWarning: filter_length (413) is longer than the signal (189), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  epochs.filter(4, 80)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 65342 out of 65342 | elapsed:   11.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-002.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-003.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-004.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-005.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-006.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-007.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-008.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-009.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-010.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-011.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-012.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-013.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-014.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-015.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-016.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-017.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ekg: ['EEG063', 'EEG064']\n",
      "heog: ['EEG061']\n",
      "veog: ['EEG062']\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n",
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Estimated head radius (1.0 cm) is below the 3rd percentile for infant head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['famous_new', 'famous_second_early', 'famous_second_late', 'scrambled_new', 'scrambled_second_early', 'scrambled_second_late', 'unfamiliar_new', 'unfamiliar_second_early', 'unfamiliar_second_late']\n",
      "Not setting metadata\n",
      "881 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 881 events and 189 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Setting up band-pass filter from 4 - 80 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 80.00 Hz\n",
      "- Upper transition bandwidth: 20.00 Hz (-6 dB cutoff frequency: 90.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:126: RuntimeWarning: filter_length (413) is longer than the signal (189), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  epochs.filter(4, 80)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 65194 out of 65194 | elapsed:   11.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-002.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-003.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-004.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-005.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-006.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-007.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-008.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-009.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-010.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-011.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-012.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-013.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-014.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-015.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-016.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-017.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-018.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ekg: ['EEG063', 'EEG064']\n",
      "heog: ['EEG061']\n",
      "veog: ['EEG062']\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n",
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: Estimated head radius (1.2 cm) is below the 3rd percentile for infant head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['famous_new', 'famous_second_early', 'famous_second_late', 'scrambled_new', 'scrambled_second_early', 'scrambled_second_late', 'unfamiliar_new', 'unfamiliar_second_early', 'unfamiliar_second_late']\n",
      "Not setting metadata\n",
      "873 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 873 events and 189 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:75: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Setting up band-pass filter from 4 - 80 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 80.00 Hz\n",
      "- Upper transition bandwidth: 20.00 Hz (-6 dB cutoff frequency: 90.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_622/4190618924.py:126: RuntimeWarning: filter_length (413) is longer than the signal (189), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  epochs.filter(4, 80)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 64602 out of 64602 | elapsed:   11.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-002.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-003.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-004.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-005.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-006.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-007.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-008.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-009.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-010.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-011.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-012.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-013.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-014.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-015.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-016.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-017.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-018.npz\n",
      "SAVED: ./data/face_recognition_preprocessed_data/data_sub-019.npz\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "# list files\n",
    "files_name_eeglab = sorted(glob.glob('./face_processing_data/*/eeg/sub-*_task-FaceRecognition_eeg.set'))\n",
    "files_name_tsv = sorted(glob.glob('./face_processing_data/sub-*/eeg/sub-*_task-FaceRecognition_events.tsv'))\n",
    "\n",
    "\n",
    "\n",
    "###############################################################\n",
    "\n",
    "def get_onset_duration(df):\n",
    "    \"\"\" This function gets the onset and duration given the df \"\"\"\n",
    "    onset = []\n",
    "    duration = []\n",
    "    trial_type = []\n",
    "    label = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if df['event_type'][i] == 'button_press':\n",
    "            if df['event_type'][i-1] == 'faces':\n",
    "                onset.append(df['onset'][i-1])\n",
    "                duration.append(df['onset'][i] - df['onset'][i-1])\n",
    "                trial_type.append(df['trial_type'][i-1])\n",
    "                label.append(df['value'][i-1])\n",
    "\n",
    "                # code to get the max duration\n",
    "                # this allows me to get a size \n",
    "                # of the window without overlaps\n",
    "                # of 1.4 seconds\n",
    "                # try:\n",
    "                #     duration_max.append(df['onset'][i+1] - df['onset'][i-1])\n",
    "                # except:\n",
    "                #     pass\n",
    "\n",
    "\n",
    "    return np.array(onset), np.array(duration), np.array(trial_type), np.array(label) # , np.array(duration_max)\n",
    "\n",
    "###############################################################\n",
    "\n",
    "def get_data_eeglab(files_name_eeglab, files_name_tsv, base_path):\n",
    "    \"\"\" This function loads the data from the eeglab files and the tsv \n",
    "    files and saves them in a npz file.\n",
    "\n",
    "    @param files_name_eeglab: list of strings\n",
    "        list of the eeglab files\n",
    "    @param files_name_tsv: list of strings\n",
    "        list of the tsv files\n",
    "    @param base_path: string\n",
    "        path where to save the data\n",
    "\n",
    "    @return: None\n",
    "    \"\"\"\n",
    "    files_name = zip(files_name_eeglab, files_name_tsv)\n",
    "\n",
    "    # target labels\n",
    "    target_labels = torch.tensor([])\n",
    "    target_trial_type = np.array([])\n",
    "    X = torch.tensor([])\n",
    "    event_dict_all = []\n",
    "    subject_id = torch.tensor([])\n",
    "\n",
    "    data = []\n",
    "    for eeglab_file, tsv in files_name:\n",
    "\n",
    "        #######################################################\n",
    "        ######## LOAD EEG DATA FROM THE EEG FILE ##############\n",
    "        #######################################################\n",
    "        # load the data\n",
    "        raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n",
    "\n",
    "\n",
    "        #######################################################\n",
    "        ######## PERFORM ICA ##################################\n",
    "        #######################################################\n",
    "\n",
    "        # perform ica and plot\n",
    "        # ica = mne.preprocessing.ICA(n_components=0.95, random_state=97, max_iter='auto')\n",
    "        # ica.fit(raw)\n",
    "\n",
    "        # ica_raw = ica.get_components()\n",
    "\n",
    "        #######################################################\n",
    "        ######## LOAD ANNOTATIONS FROM THE TSV FILE ###########\n",
    "        #######################################################\n",
    "\n",
    "        df = pd.read_csv(tsv, sep='\\t')\n",
    "\n",
    "        # get the onset and duration\n",
    "        onset, duration, trial_type, label = get_onset_duration(df)\n",
    "\n",
    "        # duration_max = np.max(duration) # 1.4s\n",
    "\n",
    "        # get the target labels\n",
    "        target_labels = torch.cat([target_labels, torch.from_numpy(label)])\n",
    "        target_trial_type = np.concatenate([target_trial_type, trial_type])\n",
    "\n",
    "        # add the annotations to the raw data\n",
    "        annot = mne.Annotations(\n",
    "            onset=list(onset),  # in seconds\n",
    "            duration=[1.4]*onset.shape[0],  # in seconds, too\n",
    "            description=list(trial_type),\n",
    "            # id_code=list(df['value']),\n",
    "        )\n",
    "\n",
    "        # print the annotations\n",
    "        # print(annot)\n",
    "\n",
    "        raw2 = raw.copy().set_annotations(annot)\n",
    "\n",
    "        # raw2.plot()\n",
    "        # print(pd.DataFrame(raw2.annotations))\n",
    "\n",
    "        # get events from the annotations\n",
    "        events_from_annot, event_dict = mne.events_from_annotations(raw2)\n",
    "\n",
    "        # epochs\n",
    "        epochs = mne.Epochs(raw2, events_from_annot, event_id=event_dict, tmin=-0.2, tmax=0.55, preload=True)\n",
    "\n",
    "        # filter the data\n",
    "        epochs.filter(4, 80)\n",
    "\n",
    "        # apply baseline correction\n",
    "        epochs.apply_baseline((None, 0))\n",
    "\n",
    "        # # plot the epochs\n",
    "        # epochs.plot(n_epochs=10, n_channels=10)\n",
    "\n",
    "        # subject id\n",
    "        subject_id = torch.cat([subject_id,torch.tensor([int(i) for i in [eeglab_file.split('/')[2].split('-')[1]]])])\n",
    "\n",
    "        # concatenate the data\n",
    "        X = torch.cat([X, torch.from_numpy(epochs.get_data()).to(torch.float32)])\n",
    "\n",
    "        # concatenate the event dict\n",
    "        event_dict_all.append(event_dict)\n",
    "\n",
    "        # Save the data\n",
    "        data.append((eeglab_file.split('/')[2], epochs.get_data(), epochs.info, epochs.events, epochs.event_id, event_dict, epochs.tmin, epochs.tmax))\n",
    "\n",
    "        for d in data:\n",
    "            print('SAVED: '+base_path + 'data_{}.npz'.format(d[0]))\n",
    "            np.savez_compressed(base_path + 'data_{}.npz'.format(d[0]), data=np.array(d[1],dtype='float32'))\n",
    "\n",
    "        # # save the data\n",
    "        torch.save(X, base_path + '/dataset/X.pt')\n",
    "        torch.save(target_labels, base_path + '/dataset/target_labels.pt')\n",
    "        # torch.save(target_trial_type, base_path + '/dataset/target_trial_type.pt')\n",
    "        np.save(base_path + '/dataset/target_trial_type.npy', target_trial_type)\n",
    "        # torch.save(subject_id, base_path + '/dataset/subject_id.pt')\n",
    "        with open(base_path + '/dataset/event_dict_all.pkl', 'wb') as f:\n",
    "            pickle.dump(event_dict_all, f)\n",
    "        \n",
    "\n",
    "base_path = './data/face_recognition_preprocessed_data/'\n",
    "get_data_eeglab(files_name_eeglab, files_name_tsv, base_path)\n",
    "\n",
    "# import pickle\n",
    "# with open('./data/face_recognition_preprocessed_data/face_recognition_preprocessed_data.pkl', 'wb') as f:\n",
    "#     pickle.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4190909000000147 0.7127023756849297 0.13363699999990786\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv('./face_processing_data/sub-002/eeg/sub-002_task-FaceRecognition_events.tsv', sep='\\t')\n",
    "\n",
    "def get_onset_duration(df):\n",
    "    \"\"\" This function gets the onset and duration given the df \"\"\"\n",
    "    onset = []\n",
    "    duration = []\n",
    "    trial_type = []\n",
    "    label = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if df['event_type'][i] == 'button_press':\n",
    "            if df['event_type'][i-1] == 'faces':\n",
    "                onset.append(df['onset'][i-1])\n",
    "                duration.append(df['onset'][i] - df['onset'][i-1])\n",
    "                trial_type.append(df['trial_type'][i-1])\n",
    "                label.append(df['value'][i-1])\n",
    "\n",
    "                # code to get the max duration\n",
    "                # this allows me to get a size \n",
    "                # of the window without overlaps\n",
    "                # of 1.4 seconds\n",
    "                # try:\n",
    "                #     duration_max.append(df['onset'][i+1] - df['onset'][i-1])\n",
    "                # except:\n",
    "                #     pass\n",
    "\n",
    "\n",
    "    return np.array(onset), np.array(duration), np.array(trial_type), np.array(label) # , np.array(duration_max)\n",
    "\n",
    "onset, duration, trial_type, label = get_onset_duration(df)\n",
    "\n",
    "print(duration.max(), duration.mean(), duration.min()) # 1.4, 0.7, 0.2 # we will use 1.419s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([int(i) for i in [files_name_eeglab[0].split('/')[2].split('-')[1]]*10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>sample</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>response_time</th>\n",
       "      <th>stim_file</th>\n",
       "      <th>value</th>\n",
       "      <th>face_type</th>\n",
       "      <th>event_type</th>\n",
       "      <th>event_order</th>\n",
       "      <th>trial_dist</th>\n",
       "      <th>time_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.205818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unfamiliar_new</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u032.bmp</td>\n",
       "      <td>13</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>faces</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.154000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_nonsym</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>button_press</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.245818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unfamiliar_second_early</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u032.bmp</td>\n",
       "      <td>14</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>faces</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.893091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>left_nonsym</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>button_press</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.353091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unfamiliar_new</td>\n",
       "      <td>NaN</td>\n",
       "      <td>u088.bmp</td>\n",
       "      <td>13</td>\n",
       "      <td>unfamiliar</td>\n",
       "      <td>faces</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>2975.132182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>famous_new</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f002.bmp</td>\n",
       "      <td>5</td>\n",
       "      <td>famous</td>\n",
       "      <td>faces</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>2975.833091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>right_sym</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>button_press</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>2978.239455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>famous_second_early</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f002.bmp</td>\n",
       "      <td>6</td>\n",
       "      <td>famous</td>\n",
       "      <td>faces</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>2978.732182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>right_sym</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>button_press</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>2981.263091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>famous_second_late</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f150.bmp</td>\n",
       "      <td>7</td>\n",
       "      <td>famous</td>\n",
       "      <td>faces</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>34.8136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1479 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            onset  duration  sample               trial_type  response_time  \\\n",
       "0       24.205818       NaN     NaN           unfamiliar_new            NaN   \n",
       "1       25.154000       NaN     NaN              left_nonsym            NaN   \n",
       "2       27.245818       NaN     NaN  unfamiliar_second_early            NaN   \n",
       "3       27.893091       NaN     NaN              left_nonsym            NaN   \n",
       "4       30.353091       NaN     NaN           unfamiliar_new            NaN   \n",
       "...           ...       ...     ...                      ...            ...   \n",
       "1474  2975.132182       NaN     NaN               famous_new            NaN   \n",
       "1475  2975.833091       NaN     NaN                right_sym            NaN   \n",
       "1476  2978.239455       NaN     NaN      famous_second_early            NaN   \n",
       "1477  2978.732182       NaN     NaN                right_sym            NaN   \n",
       "1478  2981.263091       NaN     NaN       famous_second_late            NaN   \n",
       "\n",
       "     stim_file  value   face_type    event_type  event_order  trial_dist  \\\n",
       "0     u032.bmp     13  unfamiliar         faces            1           0   \n",
       "1          NaN    256         NaN  button_press            0           0   \n",
       "2     u032.bmp     14  unfamiliar         faces            2           1   \n",
       "3          NaN    256         NaN  button_press            0           0   \n",
       "4     u088.bmp     13  unfamiliar         faces            1           0   \n",
       "...        ...    ...         ...           ...          ...         ...   \n",
       "1474  f002.bmp      5      famous         faces            1           0   \n",
       "1475       NaN   4096         NaN  button_press            0           0   \n",
       "1476  f002.bmp      6      famous         faces            2           1   \n",
       "1477       NaN   4096         NaN  button_press            0           0   \n",
       "1478  f150.bmp      7      famous         faces            2          11   \n",
       "\n",
       "      time_dist  \n",
       "0        0.0000  \n",
       "1        0.0000  \n",
       "2        3.0400  \n",
       "3        0.0000  \n",
       "4        0.0000  \n",
       "...         ...  \n",
       "1474     0.0000  \n",
       "1475     0.0000  \n",
       "1476     3.1073  \n",
       "1477     0.0000  \n",
       "1478    34.8136  \n",
       "\n",
       "[1479 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./face_processing_data/sub-002/eeg/sub-002_task-FaceRecognition_events.tsv', sep='\\t')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15392, 74, 189])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "base_path = './data/face_recognition_preprocessed_data/'\n",
    "X = torch.load(base_path + '/dataset/X.pt')\n",
    "\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_282/246143246.py:55: RuntimeWarning: Unknown types found, setting as type EEG:\n",
      "ekg: ['EEG063', 'EEG064']\n",
      "heog: ['EEG061']\n",
      "veog: ['EEG062']\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n",
      "/tmp/ipykernel_282/246143246.py:55: RuntimeWarning: Estimated head radius (1.1 cm) is below the 3rd percentile for infant head size. Check if the montage_units argument is correct (the default is \"mm\", but your channel positions may be in different units).\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['famous_new', 'famous_second_early', 'famous_second_late', 'scrambled_new', 'scrambled_second_early', 'scrambled_second_late', 'unfamiliar_new', 'unfamiliar_second_early', 'unfamiliar_second_late']\n",
      "Not setting metadata\n",
      "584 matching events found\n",
      "Setting baseline interval to [-0.2, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 584 events and 189 original time points ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_282/246143246.py:55: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n",
      "Setting up band-pass filter from 4 - 80 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 80.00 Hz\n",
      "- Upper transition bandwidth: 20.00 Hz (-6 dB cutoff frequency: 90.00 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_282/246143246.py:88: RuntimeWarning: filter_length (413) is longer than the signal (189), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  epochs.filter(4, 80)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying baseline correction (mode: mean)\n",
      "<Info | 8 non-empty values\n",
      " bads: []\n",
      " ch_names: EEG001, EEG002, EEG003, EEG004, EEG005, EEG006, EEG007, EEG008, ...\n",
      " chs: 74 EEG\n",
      " custom_ref_applied: False\n",
      " dig: 77 items (3 Cardinal, 74 EEG)\n",
      " highpass: 0.0 Hz\n",
      " lowpass: 125.0 Hz\n",
      " meas_date: unspecified\n",
      " nchan: 74\n",
      " projs: []\n",
      " sfreq: 250.0 Hz\n",
      ">\n",
      "<Info | 8 non-empty values\n",
      " bads: []\n",
      " ch_names: EEG001, EEG002, EEG003, EEG004, EEG005, EEG006, EEG007, EEG008, ...\n",
      " chs: 74 EEG\n",
      " custom_ref_applied: False\n",
      " dig: 77 items (3 Cardinal, 74 EEG)\n",
      " highpass: 4.0 Hz\n",
      " lowpass: 80.0 Hz\n",
      " meas_date: unspecified\n",
      " nchan: 74\n",
      " projs: []\n",
      " sfreq: 250.0 Hz\n",
      ">\n",
      "[-0.2   -0.196 -0.192 -0.188 -0.184 -0.18  -0.176 -0.172 -0.168 -0.164\n",
      " -0.16  -0.156 -0.152 -0.148 -0.144 -0.14  -0.136 -0.132 -0.128 -0.124\n",
      " -0.12  -0.116 -0.112 -0.108 -0.104 -0.1   -0.096 -0.092 -0.088 -0.084\n",
      " -0.08  -0.076 -0.072 -0.068 -0.064 -0.06  -0.056 -0.052 -0.048 -0.044\n",
      " -0.04  -0.036 -0.032 -0.028 -0.024 -0.02  -0.016 -0.012 -0.008 -0.004\n",
      "  0.     0.004  0.008  0.012  0.016  0.02   0.024  0.028  0.032  0.036\n",
      "  0.04   0.044  0.048  0.052  0.056  0.06   0.064  0.068  0.072  0.076\n",
      "  0.08   0.084  0.088  0.092  0.096  0.1    0.104  0.108  0.112  0.116\n",
      "  0.12   0.124  0.128  0.132  0.136  0.14   0.144  0.148  0.152  0.156\n",
      "  0.16   0.164  0.168  0.172  0.176  0.18   0.184  0.188  0.192  0.196\n",
      "  0.2    0.204  0.208  0.212  0.216  0.22   0.224  0.228  0.232  0.236\n",
      "  0.24   0.244  0.248  0.252  0.256  0.26   0.264  0.268  0.272  0.276\n",
      "  0.28   0.284  0.288  0.292  0.296  0.3    0.304  0.308  0.312  0.316\n",
      "  0.32   0.324  0.328  0.332  0.336  0.34   0.344  0.348  0.352  0.356\n",
      "  0.36   0.364  0.368  0.372  0.376  0.38   0.384  0.388  0.392  0.396\n",
      "  0.4    0.404  0.408  0.412  0.416  0.42   0.424  0.428  0.432  0.436\n",
      "  0.44   0.444  0.448  0.452  0.456  0.46   0.464  0.468  0.472  0.476\n",
      "  0.48   0.484  0.488  0.492  0.496  0.5    0.504  0.508  0.512  0.516\n",
      "  0.52   0.524  0.528  0.532  0.536  0.54   0.544  0.548  0.552]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 43216 out of 43216 | elapsed:    8.3s finished\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "# list files\n",
    "files_name_eeglab = sorted(glob.glob('./face_processing_data/*/eeg/sub-*_task-FaceRecognition_eeg.set'))\n",
    "files_name_tsv = sorted(glob.glob('./face_processing_data/sub-*/eeg/sub-*_task-FaceRecognition_events.tsv'))\n",
    "\n",
    "\n",
    "\n",
    "def get_onset_duration(df):\n",
    "    \"\"\" This function gets the onset and duration given the df \"\"\"\n",
    "    onset = []\n",
    "    duration = []\n",
    "    trial_type = []\n",
    "    label = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        if df['event_type'][i] == 'button_press':\n",
    "            if df['event_type'][i-1] == 'faces':\n",
    "                onset.append(df['onset'][i-1])\n",
    "                duration.append(df['onset'][i] - df['onset'][i-1])\n",
    "                trial_type.append(df['trial_type'][i-1])\n",
    "                label.append(df['value'][i-1])\n",
    "\n",
    "                # code to get the max duration\n",
    "                # this allows me to get a size \n",
    "                # of the window without overlaps\n",
    "                # of 1.4 seconds\n",
    "                # try:\n",
    "                #     duration_max.append(df['onset'][i+1] - df['onset'][i-1])\n",
    "                # except:\n",
    "                #     pass\n",
    "\n",
    "\n",
    "    return np.array(onset), np.array(duration), np.array(trial_type), np.array(label) # , np.array(duration_max)\n",
    "\n",
    "\n",
    "def get_data_eeglab(files_name_eeglab, files_name_tsv, base_path):\n",
    "    \"\"\" \n",
    "    \"\"\"\n",
    "    files_name = zip(files_name_eeglab, files_name_tsv)\n",
    "\n",
    "    for eeglab_file, tsv in files_name:\n",
    "\n",
    "        #######################################################\n",
    "        ######## LOAD EEG DATA FROM THE EEG FILE ##############\n",
    "        #######################################################\n",
    "        # load the data\n",
    "        raw = mne.io.read_raw_eeglab(eeglab_file, preload=True)\n",
    "\n",
    "        df = pd.read_csv(tsv, sep='\\t')\n",
    "\n",
    "        # get the onset and duration\n",
    "        onset, duration, trial_type, label = get_onset_duration(df)\n",
    "\n",
    "        # duration_max = np.max(duration) # 1.4s\n",
    "\n",
    "\n",
    "        # add the annotations to the raw data\n",
    "        annot = mne.Annotations(\n",
    "            onset=list(onset),  # in seconds\n",
    "            duration=[1.4]*onset.shape[0],  # in seconds, too\n",
    "            description=list(trial_type),\n",
    "            # id_code=list(df['value']),\n",
    "        )\n",
    "\n",
    "        # print the annotations\n",
    "        # print(annot)\n",
    "\n",
    "        raw2 = raw.copy().set_annotations(annot)\n",
    "\n",
    "        # raw2.plot()\n",
    "        # print(pd.DataFrame(raw2.annotations))\n",
    "\n",
    "        # get events from the annotations\n",
    "        events_from_annot, event_dict = mne.events_from_annotations(raw2)\n",
    "\n",
    "        # epochs\n",
    "        epochs = mne.Epochs(raw2, events_from_annot, event_id=event_dict, tmin=-0.2, tmax=0.55, preload=True)\n",
    "\n",
    "        # filter the data\n",
    "        epochs.filter(4, 80)\n",
    "\n",
    "        # apply baseline correction\n",
    "        epochs.apply_baseline((None, 0))\n",
    "\n",
    "        print(raw.info)\n",
    "        print(epochs.info)\n",
    "        print(epochs.times)\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "base_path = './data/face_recognition_preprocessed_data/'\n",
    "get_data_eeglab(files_name_eeglab, files_name_tsv, base_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
